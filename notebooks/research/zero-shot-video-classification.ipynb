{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4fe8ce3-5251-4aac-bc8e-55d13db5c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`id2label` is found in both `text_config_dict` and `text_config` but with different values. The value `text_config_dict[\"id2label\"]` will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching examples at: '/home/ec2-user/SageMaker/transcribe-podcast-speaker-verification/notebooks/gradio_cached_examples/52'\n",
      "Caching example 1/3\n",
      "Caching example 2/3\n",
      "Caching example 3/3\n",
      "Caching complete\n",
      "\n",
      "Running on local URL:  http://127.0.0.1:6006\n",
      "Running on public URL: https://a6cd4c34ca1347cc7d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a6cd4c34ca1347cc7d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from utils import (\n",
    "    convert_frames_to_gif,\n",
    "    download_youtube_video,\n",
    "    get_num_total_frames,\n",
    "    sample_frames_from_video_file,\n",
    ")\n",
    "\n",
    "FRAME_SAMPLING_RATE = 4\n",
    "DEFAULT_MODEL = \"microsoft/xclip-base-patch16-zero-shot\"\n",
    "\n",
    "VALID_ZEROSHOT_VIDEOCLASSIFICATION_MODELS = [\n",
    "    \"microsoft/xclip-base-patch32\",\n",
    "    \"microsoft/xclip-base-patch16-zero-shot\",\n",
    "    \"microsoft/xclip-base-patch16-kinetics-600\",\n",
    "    \"microsoft/xclip-large-patch14ft/xclip-base-patch32-16-frames\",\n",
    "    \"microsoft/xclip-large-patch14\",\n",
    "    \"microsoft/xclip-base-patch16-hmdb-4-shot\",\n",
    "    \"microsoft/xclip-base-patch16-16-frames\",\n",
    "    \"microsoft/xclip-base-patch16-hmdb-2-shot\",\n",
    "    \"microsoft/xclip-base-patch16-ucf-2-shot\",\n",
    "    \"microsoft/xclip-base-patch16-ucf-8-shot\",\n",
    "    \"microsoft/xclip-base-patch16\",\n",
    "    \"microsoft/xclip-base-patch16-hmdb-8-shot\",\n",
    "    \"microsoft/xclip-base-patch16-hmdb-16-shot\",\n",
    "    \"microsoft/xclip-base-patch16-ucf-16-shot\",\n",
    "]\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(DEFAULT_MODEL)\n",
    "model = AutoModel.from_pretrained(DEFAULT_MODEL)\n",
    "\n",
    "examples = [\n",
    "    [\n",
    "        \"https://www.youtu.be/l1dBM8ZECao\",\n",
    "        \"sleeping dog,cat fight club,birds of prey\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://youtu.be/VMj-3S1tku0\",\n",
    "        \"programming course,eating spaghetti,playing football\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://youtu.be/Tm6BlRMEny0\",\n",
    "        \"game of thrones,the lord of the rings,vikings\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "def select_model(model_name):\n",
    "    global processor, model\n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def predict(youtube_url_or_file_path, labels_text):\n",
    "\n",
    "    if youtube_url_or_file_path.startswith(\"http\"):\n",
    "        video_path = download_youtube_video(youtube_url_or_file_path)\n",
    "    else:\n",
    "        video_path = youtube_url_or_file_path\n",
    "\n",
    "    # rearrange sampling rate based on video length and model input length\n",
    "    num_total_frames = get_num_total_frames(video_path)\n",
    "    num_model_input_frames = model.config.vision_config.num_frames\n",
    "    if num_total_frames < FRAME_SAMPLING_RATE * num_model_input_frames:\n",
    "        frame_sampling_rate = num_total_frames // num_model_input_frames\n",
    "    else:\n",
    "        frame_sampling_rate = FRAME_SAMPLING_RATE\n",
    "\n",
    "    labels = labels_text.split(\",\")\n",
    "\n",
    "    frames = sample_frames_from_video_file(\n",
    "        video_path, num_model_input_frames, frame_sampling_rate\n",
    "    )\n",
    "    gif_path = convert_frames_to_gif(frames, save_path=\"video.gif\")\n",
    "\n",
    "    inputs = processor(\n",
    "        text=labels, videos=list(frames), return_tensors=\"pt\", padding=True\n",
    "    )\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probs = outputs.logits_per_video[0].softmax(dim=-1).cpu().numpy()\n",
    "    label_to_prob = {}\n",
    "    for ind, label in enumerate(labels):\n",
    "        label_to_prob[label] = float(probs[ind])\n",
    "\n",
    "    return label_to_prob, gif_path\n",
    "\n",
    "\n",
    "app = gr.Blocks()\n",
    "with app:\n",
    "    gr.Markdown(\n",
    "        \"# **<p align='center'>Zero-shot Video Classification with ðŸ¤— Transformers</p>**\"\n",
    "    )\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        <p style='text-align: center'>\n",
    "        Follow me for more! \n",
    "        <br> <a href='https://twitter.com/fcakyon' target='_blank'>twitter</a> | <a href='https://github.com/fcakyon' target='_blank'>github</a> | <a href='https://www.linkedin.com/in/fcakyon/' target='_blank'>linkedin</a> | <a href='https://fcakyon.medium.com/' target='_blank'>medium</a>\n",
    "        </p>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            model_names_dropdown = gr.Dropdown(\n",
    "                choices=VALID_ZEROSHOT_VIDEOCLASSIFICATION_MODELS,\n",
    "                label=\"Model:\",\n",
    "                show_label=True,\n",
    "                value=DEFAULT_MODEL,\n",
    "            )\n",
    "            model_names_dropdown.change(fn=select_model, inputs=model_names_dropdown)\n",
    "            with gr.Tab(label=\"Youtube URL\"):\n",
    "                gr.Markdown(\n",
    "                    \"### **Provide a Youtube video URL and a list of labels separated by commas**\"\n",
    "                )\n",
    "                youtube_url = gr.Textbox(label=\"Youtube URL:\", show_label=True)\n",
    "                youtube_url_labels_text = gr.Textbox(\n",
    "                    label=\"Labels Text:\", show_label=True\n",
    "                )\n",
    "                youtube_url_predict_btn = gr.Button(value=\"Predict\")\n",
    "            with gr.Tab(label=\"Local File\"):\n",
    "                gr.Markdown(\n",
    "                    \"### **Upload a video file and provide a list of labels separated by commas**\"\n",
    "                )\n",
    "                video_file = gr.Video(label=\"Video File:\", show_label=True)\n",
    "                local_video_labels_text = gr.Textbox(\n",
    "                    label=\"Labels Text:\", show_label=True\n",
    "                )\n",
    "                local_video_predict_btn = gr.Button(value=\"Predict\")\n",
    "        with gr.Column():\n",
    "            video_gif = gr.Image(\n",
    "                label=\"Input Clip\",\n",
    "                show_label=True,\n",
    "            )\n",
    "        with gr.Column():\n",
    "            predictions = gr.Label(label=\"Predictions:\", show_label=True)\n",
    "\n",
    "    gr.Markdown(\"**Examples:**\")\n",
    "    gr.Examples(\n",
    "        examples,\n",
    "        [youtube_url, youtube_url_labels_text],\n",
    "        [predictions, video_gif],\n",
    "        fn=predict,\n",
    "        cache_examples=True,\n",
    "    )\n",
    "\n",
    "    youtube_url_predict_btn.click(\n",
    "        predict,\n",
    "        inputs=[youtube_url, youtube_url_labels_text],\n",
    "        outputs=[predictions, video_gif],\n",
    "    )\n",
    "    local_video_predict_btn.click(\n",
    "        predict,\n",
    "        inputs=[video_file, local_video_labels_text],\n",
    "        outputs=[predictions, video_gif],\n",
    "    )\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        \\n Demo created by: <a href=\\\"https://github.com/fcakyon\\\">fcakyon</a>.\n",
    "        <br> Based on this <a href=\\\"https://huggingface.co/docs/transformers/main/model_doc/xclip\">HuggingFace model</a>.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "app.launch(share=True, server_port=6006, inline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9a3ab-932b-49fe-9c1c-488f852ec44c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_machinelearnear-dev",
   "language": "python",
   "name": "conda_machinelearnear-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
